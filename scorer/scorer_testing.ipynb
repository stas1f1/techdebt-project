{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e782bfb8-ec63-4484-8029-84a94ba2bf9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc37946-58e2-4b85-bf8d-e5c609a90d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "import ast\n",
    "import astunparse\n",
    "\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68409096-9950-40ba-83b1-3b9723bc5a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr  9 11:54:07 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.126.02   Driver Version: 418.126.02   CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    58W / 300W |   2428MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ae13f-e6aa-461e-a20f-4fadfcf1eaa2",
   "metadata": {},
   "source": [
    "Load and test epoch 4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c43272-099a-4bcc-9ca9-5cbf628c2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('checkpoingnts/R2-checkpoint-18000')\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e61e70b2-c30a-4d78-9cf5-e2a5e320b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_info(functionNode):\n",
    "    functionName = functionNode.name\n",
    "    functionArgs = [arg.arg for arg in functionNode.args.args]\n",
    "    functionCode = astunparse.unparse(functionNode)\n",
    "    return [functionName, functionArgs, functionCode]\n",
    "\n",
    "def code_to_functions_df(code):\n",
    "    node = ast.parse(code)\n",
    "    functions = [n for n in node.body if isinstance(n, ast.FunctionDef)]\n",
    "    classes = [n for n in node.body if isinstance(n, ast.ClassDef)]\n",
    "\n",
    "    standalone_functions = [get_function_info(function) for function in functions]\n",
    "    \n",
    "    class_functions = []\n",
    "        \n",
    "    for class_ in classes:\n",
    "        methods = [n for n in class_.body if isinstance(n, ast.FunctionDef)]\n",
    "        cur_class_functions = [get_function_info(method) for method in methods]\n",
    "        class_functions.extend(cur_class_functions)\n",
    "    \n",
    "    return pd.DataFrame(standalone_functions + class_functions,\n",
    "                      columns =['functionName', 'functionArgs', 'functionCode'])\n",
    "\n",
    "def file_to_processed_df(filename):\n",
    "    functions = []\n",
    "    with open(filename) as file:\n",
    "        functions = code_to_functions_df(file.read())\n",
    "    #preprocess - remove all before args definition\n",
    "    functions['functionCode'] = [s[s.find('('):] for s in functions['functionCode']]\n",
    "    return functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7992d37-6f35-4d39-9f6b-ba229fe4b3cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test 1 - Looking at good code\n",
    "We look at test module code from Philips' library for extracting functions from GitHub repos, all functions are correct, how will model recognize them?\n",
    "\n",
    "source: https://github.com/philips-software/functiondefextractor/blob/master/test/test_core_extractor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f71591f-e2fa-4781-a201-a3bc8d15f9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionName</th>\n",
       "      <th>functionArgs</th>\n",
       "      <th>functionCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get_log_data</td>\n",
       "      <td>[line]</td>\n",
       "      <td>(line):\\n    ' function to get the line reques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_filter_reg_files</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test filter_reg_file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_get_function_names</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test get_function_na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_get_func_body</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test get_function_bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_process_ad</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test the complete en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_process_extract</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test the complete en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_process_annot</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test the complete en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_process_python_test_extract</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test the complete en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_invalid_path</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test valid input pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_py_annot_method_names</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test python annoted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_get_report</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test report generate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_pivot_table</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test pivot table'\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_cmd_inputs</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test command line in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_extractor_cmd</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test command line wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        functionName functionArgs  \\\n",
       "0                       get_log_data       [line]   \n",
       "1              test_filter_reg_files       [self]   \n",
       "2            test_get_function_names       [self]   \n",
       "3                 test_get_func_body       [self]   \n",
       "4                    test_process_ad       [self]   \n",
       "5               test_process_extract       [self]   \n",
       "6                 test_process_annot       [self]   \n",
       "7   test_process_python_test_extract       [self]   \n",
       "8                  test_invalid_path       [self]   \n",
       "9         test_py_annot_method_names       [self]   \n",
       "10                   test_get_report       [self]   \n",
       "11                  test_pivot_table       [self]   \n",
       "12                   test_cmd_inputs       [self]   \n",
       "13                test_extractor_cmd       [self]   \n",
       "\n",
       "                                         functionCode  \n",
       "0   (line):\\n    ' function to get the line reques...  \n",
       "1   (self):\\n    'Function to test filter_reg_file...  \n",
       "2   (self):\\n    'Function to test get_function_na...  \n",
       "3   (self):\\n    'Function to test get_function_bo...  \n",
       "4   (self):\\n    'Function to test the complete en...  \n",
       "5   (self):\\n    'Function to test the complete en...  \n",
       "6   (self):\\n    'Function to test the complete en...  \n",
       "7   (self):\\n    'Function to test the complete en...  \n",
       "8   (self):\\n    'Function to test valid input pat...  \n",
       "9   (self):\\n    'Function to test python annoted ...  \n",
       "10  (self):\\n    'Function to test report generate...  \n",
       "11  (self):\\n    'Function to test pivot table'\\n ...  \n",
       "12  (self):\\n    'Function to test command line in...  \n",
       "13  (self):\\n    'Function to test command line wo...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions = file_to_processed_df(\"code_sample/code_sample.py\")\n",
    "functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537dc88-7220-4ba9-92a4-28aadccce9c9",
   "metadata": {},
   "source": [
    "So, the final result should look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ccf0d57-b7c2-4823-98f9-7a9f2587642f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.LongTensor(14 * [0])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08ca0b4d-17f6-4492-b12d-ec6f137f6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([n + tokenizer.sep_token + c for n,c in functions[['functionName', 'functionCode']].values],\n",
    "                         return_tensors='pt', max_length=512,\n",
    "                         truncation=True, padding='max_length')\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0ea38e6-4b15-4bbf-863f-78bdf69e1f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Prediction: {torch.argmax(outputs['logits'], dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a7aa3-4104-4d58-b1aa-050a95cd2fb0",
   "metadata": {},
   "source": [
    "All guessed correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812cfafe-84ea-4c9a-a1ba-ac4ce252cdcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test 2 - Shuffle on that name\n",
    "Same code but every 2nd func name is incorrect - manually shuffled with other ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60eec763-c3a7-4bd1-b177-0a4e3d855cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionName</th>\n",
       "      <th>functionArgs</th>\n",
       "      <th>functionCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get_log_data</td>\n",
       "      <td>[line]</td>\n",
       "      <td>(line):\\n    ' function to get the line reques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_get_func_body</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test filter_reg_file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_get_function_names</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test get_function_na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_process_python_test_extract</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test get_function_bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_process_ad</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test the complete en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_process_annot</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test the complete en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_process_extract</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test the complete en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_filter_reg_files</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test the complete en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_invalid_path</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test valid input pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_extractor_cmd</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test python annoted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_get_report</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test report generate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_py_annot_method_names</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test pivot table'\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_cmd_inputs</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test command line in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_pivot_table</td>\n",
       "      <td>[self]</td>\n",
       "      <td>(self):\\n    'Function to test command line wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        functionName functionArgs  \\\n",
       "0                       get_log_data       [line]   \n",
       "1                 test_get_func_body       [self]   \n",
       "2            test_get_function_names       [self]   \n",
       "3   test_process_python_test_extract       [self]   \n",
       "4                    test_process_ad       [self]   \n",
       "5                 test_process_annot       [self]   \n",
       "6               test_process_extract       [self]   \n",
       "7              test_filter_reg_files       [self]   \n",
       "8                  test_invalid_path       [self]   \n",
       "9                 test_extractor_cmd       [self]   \n",
       "10                   test_get_report       [self]   \n",
       "11        test_py_annot_method_names       [self]   \n",
       "12                   test_cmd_inputs       [self]   \n",
       "13                  test_pivot_table       [self]   \n",
       "\n",
       "                                         functionCode  \n",
       "0   (line):\\n    ' function to get the line reques...  \n",
       "1   (self):\\n    'Function to test filter_reg_file...  \n",
       "2   (self):\\n    'Function to test get_function_na...  \n",
       "3   (self):\\n    'Function to test get_function_bo...  \n",
       "4   (self):\\n    'Function to test the complete en...  \n",
       "5   (self):\\n    'Function to test the complete en...  \n",
       "6   (self):\\n    'Function to test the complete en...  \n",
       "7   (self):\\n    'Function to test the complete en...  \n",
       "8   (self):\\n    'Function to test valid input pat...  \n",
       "9   (self):\\n    'Function to test python annoted ...  \n",
       "10  (self):\\n    'Function to test report generate...  \n",
       "11  (self):\\n    'Function to test pivot table'\\n ...  \n",
       "12  (self):\\n    'Function to test command line in...  \n",
       "13  (self):\\n    'Function to test command line wo...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions = file_to_processed_df(\"code_sample/code_sample_halfmashed.py\")\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64830937-36bb-4fbb-8986-7a4cc67f3a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.LongTensor(7 * [0, 1])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24156660-edbc-4d3f-887b-d1a68e2d8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([n + tokenizer.sep_token + c for n,c in functions[['functionName', 'functionCode']].values],\n",
    "                         return_tensors='pt', max_length=512,\n",
    "                         truncation=True, padding='max_length')\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e33e33d-565b-4daa-8d2b-dbc1396e8ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
      "The F1 score is: 1.0\n"
     ]
    }
   ],
   "source": [
    "results = torch.argmax(outputs['logits'], dim=1)\n",
    "\n",
    "print(f\"Prediction: {results}\")\n",
    "print (f\"The F1 score is: {f1_score(labels, results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a11f62b7-f652-4c36-8e7a-dc757bd5ef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.8380, -3.9264],\n",
       "        [-2.5123,  2.1762],\n",
       "        [ 3.9297, -4.0873],\n",
       "        [-3.7171,  3.7810],\n",
       "        [ 2.9823, -2.6671],\n",
       "        [-1.7128,  1.1522],\n",
       "        [ 3.7639, -3.8097],\n",
       "        [-3.7143,  3.7712],\n",
       "        [ 3.7294, -3.7613],\n",
       "        [-2.1930,  1.7692],\n",
       "        [ 3.7019, -3.7025],\n",
       "        [-3.7071,  3.7530],\n",
       "        [ 3.8992, -4.0322],\n",
       "        [-3.7218,  3.7915]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['logits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233f430-7bde-43ae-bda9-935e16d5f36c",
   "metadata": {},
   "source": [
    "It was pretty certain in most cases too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33056646-3cc1-448b-8f84-a825226e140c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test 3 - Spelling errors, on big function corpus\n",
    "\n",
    "For this test, we will use later part of the python code dataset (post-100k),\n",
    "which was not used in the train/val. Let's imagine that we have a __VERY__ nervous\n",
    "programmer working, and he makes syntactic mistakes (usually - _adds or replaces_ random 1-3\n",
    "characters within the function name, in around half of the cases. How much will \n",
    "we be able to detect? \n",
    "\n",
    "We will use around 10k functions for this test.\n",
    "To keep things consistent we will still remove functions like \\_\\_init\\_\\_ and\n",
    "\\_\\_getitem\\_\\_, however in experiment part __a__ we will __not__ remove ones that\n",
    "exceed 512 tokens, truncating them, and ccompare with part __b__ where we will"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039d147f-3f64-4763-8723-a246008d5fb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test 3 setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293def30-4c8b-4fa1-9e96-273a592d6d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def add_typos(function_name):\n",
    "    rounds = random.choice(range(1,4))\n",
    "    for i in range(rounds):\n",
    "    \n",
    "        #True - typo, False - insert\n",
    "        is_typo = random.choice([True,False])\n",
    "        \n",
    "        shift = -1 if is_typo else 0\n",
    "\n",
    "        slot = random.choice(range(len(function_name)))\n",
    "        function_name = function_name[:max(0,slot + shift)] + random.choice(string.ascii_lowercase) + function_name[slot:]\n",
    "        \n",
    "    return function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e06b3fbf-6326-4ebc-903d-1dc258a8c625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add_uypos_into_funcbiojName'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_typos(\"add_typos_into_functionName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e9b5095-8513-4643-8ae8-ccdd4a76486c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionName</th>\n",
       "      <th>functionArgs</th>\n",
       "      <th>functionCode</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>load_label</td>\n",
       "      <td>[label_file]</td>\n",
       "      <td>(label_file):\\n    with open(label_file) as f:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>load_content</td>\n",
       "      <td>[file_name]</td>\n",
       "      <td>(file_name):\\n    with open(file_name) as f:\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_spawn_aspell</td>\n",
       "      <td>[self, aspell_executable, language]</td>\n",
       "      <td>(self, aspell_executable, language):\\n    args...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find_misspelled_words</td>\n",
       "      <td>[self, list_of_words, max_words]</td>\n",
       "      <td>(self, list_of_words, max_words=None):\\n    ' ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suggestions_for_word</td>\n",
       "      <td>[self, word, max_suggestions]</td>\n",
       "      <td>(self, word, max_suggestions=None):\\n    ' Che...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>transform_anagramically</td>\n",
       "      <td>[L]</td>\n",
       "      <td>(L):\\n    d = {}\\n    for e in L:\\n        se ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14850</th>\n",
       "      <td>permutation_representation</td>\n",
       "      <td>[s1, s2]</td>\n",
       "      <td>(s1, s2):\\n    assert (set(s1) == set(s2))\\n  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14851</th>\n",
       "      <td>find_largest_sq_ana</td>\n",
       "      <td>[tass, squares]</td>\n",
       "      <td>(tass, squares):\\n    S = []\\n    for s in tas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14852</th>\n",
       "      <td>find_ana_sq</td>\n",
       "      <td>[tass, squares]</td>\n",
       "      <td>(tass, squares):\\n    all_sq_ana = find_larges...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14853</th>\n",
       "      <td>from_docker_envvars</td>\n",
       "      <td>[config]</td>\n",
       "      <td>(config):\\n    if ('PG_PORT' in os.environ):\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14854 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     functionName                         functionArgs  \\\n",
       "0                      load_label                         [label_file]   \n",
       "1                    load_content                          [file_name]   \n",
       "2                   _spawn_aspell  [self, aspell_executable, language]   \n",
       "3           find_misspelled_words     [self, list_of_words, max_words]   \n",
       "4            suggestions_for_word        [self, word, max_suggestions]   \n",
       "...                           ...                                  ...   \n",
       "14849     transform_anagramically                                  [L]   \n",
       "14850  permutation_representation                             [s1, s2]   \n",
       "14851         find_largest_sq_ana                      [tass, squares]   \n",
       "14852                 find_ana_sq                      [tass, squares]   \n",
       "14853         from_docker_envvars                             [config]   \n",
       "\n",
       "                                            functionCode  label  \n",
       "0      (label_file):\\n    with open(label_file) as f:...      0  \n",
       "1      (file_name):\\n    with open(file_name) as f:\\n...      0  \n",
       "2      (self, aspell_executable, language):\\n    args...      0  \n",
       "3      (self, list_of_words, max_words=None):\\n    ' ...      0  \n",
       "4      (self, word, max_suggestions=None):\\n    ' Che...      0  \n",
       "...                                                  ...    ...  \n",
       "14849  (L):\\n    d = {}\\n    for e in L:\\n        se ...      0  \n",
       "14850  (s1, s2):\\n    assert (set(s1) == set(s2))\\n  ...      0  \n",
       "14851  (tass, squares):\\n    S = []\\n    for s in tas...      0  \n",
       "14852  (tass, squares):\\n    all_sq_ana = find_larges...      0  \n",
       "14853  (config):\\n    if ('PG_PORT' in os.environ):\\n...      0  \n",
       "\n",
       "[14854 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giga_df = pd.read_parquet(\"pyfunc_272k.parquet\")\n",
    "\n",
    "#take last 20k\n",
    "giga_df = giga_df.tail(20000)\n",
    "\n",
    "#filter ones that have tags and have function decorators\n",
    "filt_df = giga_df[giga_df['functionCode'].str.startswith(\"\\n\\ndef \")]\n",
    "filt_df = filt_df[~filt_df['functionName'].str.startswith(\"__\")].reset_index(drop=True)\n",
    "\n",
    "#preprocess body\n",
    "filt_df['functionCode'] = [s[s.find('('):] for s in filt_df['functionCode']]\n",
    "\n",
    "filt_df['label'] = 0\n",
    "\n",
    "filt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd357f-c4b0-42c3-adef-3a1397f7ba4e",
   "metadata": {},
   "source": [
    "Now let's add errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e9317ba-4e37-4e91-85ce-c9a7184a2779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8343        test___str___with_fragment\n",
      "10422                       _switch_db\n",
      "14839    parse_packet_with_fingerprint\n",
      "9198                          freevars\n",
      "3529                           LibName\n",
      "Name: functionName, dtype: object \n",
      "\n",
      "8343         tenst___stn___with_fragment\n",
      "10422                        _sswitch_db\n",
      "14839    parse_upacket_with_fingverprint\n",
      "9198                           frejfarps\n",
      "3529                            LzibNpme\n",
      "Name: functionName, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61518/3607852433.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filt_df['functionName'][rand_idx] = [add_typos(name) for name in filt_df.iloc[rand_idx]['functionName']]\n",
      "/tmp/ipykernel_61518/3607852433.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filt_df['label'][rand_idx] = 1\n"
     ]
    }
   ],
   "source": [
    "rand_idx = filt_df.sample(frac = 0.5)['functionName'].index\n",
    "print(filt_df.iloc[rand_idx[:5]]['functionName'], '\\n')\n",
    "filt_df['functionName'][rand_idx] = [add_typos(name) for name in filt_df.iloc[rand_idx]['functionName']]\n",
    "filt_df['label'][rand_idx] = 1\n",
    "\n",
    "print(filt_df.iloc[rand_idx[:5]]['functionName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "672b3fa3-119e-4ce6-831b-d06c6e090b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14854/14854 [00:29<00:00, 511.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionName</th>\n",
       "      <th>functionArgs</th>\n",
       "      <th>functionCode</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenizedStr</th>\n",
       "      <th>tokenizedStrLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>load_label</td>\n",
       "      <td>[label_file]</td>\n",
       "      <td>(label_file):\\n    with open(label_file) as f:...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>load_content</td>\n",
       "      <td>[file_name]</td>\n",
       "      <td>(file_name):\\n    with open(file_name) as f:\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_spawn_aspell</td>\n",
       "      <td>[self, aspell_executable, language]</td>\n",
       "      <td>(self, aspell_executable, language):\\n    args...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find_misspelled_words</td>\n",
       "      <td>[self, list_of_words, max_words]</td>\n",
       "      <td>(self, list_of_words, max_words=None):\\n    ' ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suggestions_for_word</td>\n",
       "      <td>[self, word, max_suggestions]</td>\n",
       "      <td>(self, word, max_suggestions=None):\\n    ' Che...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>transform_anagramically</td>\n",
       "      <td>[L]</td>\n",
       "      <td>(L):\\n    d = {}\\n    for e in L:\\n        se ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14850</th>\n",
       "      <td>permutation_representation</td>\n",
       "      <td>[s1, s2]</td>\n",
       "      <td>(s1, s2):\\n    assert (set(s1) == set(s2))\\n  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14851</th>\n",
       "      <td>find_largwst_sq_ana</td>\n",
       "      <td>[tass, squares]</td>\n",
       "      <td>(tass, squares):\\n    S = []\\n    for s in tas...</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14852</th>\n",
       "      <td>findeonadsq</td>\n",
       "      <td>[tass, squares]</td>\n",
       "      <td>(tass, squares):\\n    all_sq_ana = find_larges...</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14853</th>\n",
       "      <td>from_docker_envvars</td>\n",
       "      <td>[config]</td>\n",
       "      <td>(config):\\n    if ('PG_PORT' in os.environ):\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14854 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     functionName                         functionArgs  \\\n",
       "0                      load_label                         [label_file]   \n",
       "1                    load_content                          [file_name]   \n",
       "2                   _spawn_aspell  [self, aspell_executable, language]   \n",
       "3           find_misspelled_words     [self, list_of_words, max_words]   \n",
       "4            suggestions_for_word        [self, word, max_suggestions]   \n",
       "...                           ...                                  ...   \n",
       "14849     transform_anagramically                                  [L]   \n",
       "14850  permutation_representation                             [s1, s2]   \n",
       "14851         find_largwst_sq_ana                      [tass, squares]   \n",
       "14852                 findeonadsq                      [tass, squares]   \n",
       "14853         from_docker_envvars                             [config]   \n",
       "\n",
       "                                            functionCode  label  \\\n",
       "0      (label_file):\\n    with open(label_file) as f:...      0   \n",
       "1      (file_name):\\n    with open(file_name) as f:\\n...      0   \n",
       "2      (self, aspell_executable, language):\\n    args...      0   \n",
       "3      (self, list_of_words, max_words=None):\\n    ' ...      0   \n",
       "4      (self, word, max_suggestions=None):\\n    ' Che...      0   \n",
       "...                                                  ...    ...   \n",
       "14849  (L):\\n    d = {}\\n    for e in L:\\n        se ...      0   \n",
       "14850  (s1, s2):\\n    assert (set(s1) == set(s2))\\n  ...      0   \n",
       "14851  (tass, squares):\\n    S = []\\n    for s in tas...      1   \n",
       "14852  (tass, squares):\\n    all_sq_ana = find_larges...      1   \n",
       "14853  (config):\\n    if ('PG_PORT' in os.environ):\\n...      0   \n",
       "\n",
       "                      tokenizedStr  tokenizedStrLen  \n",
       "0      [input_ids, attention_mask]               42  \n",
       "1      [input_ids, attention_mask]               39  \n",
       "2      [input_ids, attention_mask]              153  \n",
       "3      [input_ids, attention_mask]              146  \n",
       "4      [input_ids, attention_mask]              163  \n",
       "...                            ...              ...  \n",
       "14849  [input_ids, attention_mask]               81  \n",
       "14850  [input_ids, attention_mask]              134  \n",
       "14851  [input_ids, attention_mask]              146  \n",
       "14852  [input_ids, attention_mask]              453  \n",
       "14853  [input_ids, attention_mask]              479  \n",
       "\n",
       "[14854 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_df['tokenizedStr'] = [tokenizer(n + tokenizer.sep_token + c, max_length = 512, truncation = True, return_tensors ='pt') for n,c in tqdm(filt_df[['functionName', 'functionCode']].values)]\n",
    "filt_df['tokenizedStrLen'] = [len(x['input_ids'][0]) for x in filt_df['tokenizedStr']]\n",
    "filt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21ab3b8f-24dd-4b64-a42c-b1ad9e4e27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ab37a12-69e1-4e04-a074-e04a5e279366",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df_tr = filt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9657013-b8cf-4d4f-9b75-666b46f62960",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = tokenizer([n + tokenizer.sep_token + c for n,c in filt_df_tr[['functionName', 'functionCode']].values],\n",
    "                         return_tensors='pt', max_length=512,\n",
    "                         truncation=True, padding='max_length')\n",
    "inputs_test['labels'] = torch.LongTensor([filt_df_tr['label'].to_list()]).T\n",
    "dataset_test = FunctionsDataset(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36941c8a-4f78-46c0-bb6a-8d223dddae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bf09a-fa83-4477-978a-2ebdc27ac617",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test 3a - Anylength%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10c959ca-7b7c-445c-9092-c2c5a71d6177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14854\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_61518/2919874237.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='929' max='929' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [929/929 02:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.7259203  0.55287865]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.60822491 0.8079213 ]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90009425 0.42022351]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.182441473007202,\n",
       " 'eval_accuracy': 0.6601588797630268,\n",
       " 'eval_f1': array([0.7259203 , 0.55287865]),\n",
       " 'eval_precision': array([0.60822491, 0.8079213 ]),\n",
       " 'eval_recall': array([0.90009425, 0.42022351]),\n",
       " 'eval_runtime': 149.5009,\n",
       " 'eval_samples_per_second': 99.357,\n",
       " 'eval_steps_per_second': 6.214}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "                                  per_device_eval_batch_size = 16, output_dir = \"test_3a\"\n",
    "                                 )\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer_a = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=dataset_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_a.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5453791-823f-4b1d-9e7a-868797d30355",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test 3b - Ones That Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754900a-1cc1-4c8a-8319-d03b906bcaf0",
   "metadata": {},
   "source": [
    "Now let's evaluate only on function defs that fit into 512 token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04c2c25a-5a22-4840-9913-eb4f1c9d6d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>functionName</th>\n",
       "      <th>functionArgs</th>\n",
       "      <th>functionCode</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenizedStr</th>\n",
       "      <th>tokenizedStrLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>load_label</td>\n",
       "      <td>[label_file]</td>\n",
       "      <td>(label_file):\\n    with open(label_file) as f:...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>load_content</td>\n",
       "      <td>[file_name]</td>\n",
       "      <td>(file_name):\\n    with open(file_name) as f:\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_spawn_aspell</td>\n",
       "      <td>[self, aspell_executable, language]</td>\n",
       "      <td>(self, aspell_executable, language):\\n    args...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>find_misspelled_words</td>\n",
       "      <td>[self, list_of_words, max_words]</td>\n",
       "      <td>(self, list_of_words, max_words=None):\\n    ' ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suggestions_for_word</td>\n",
       "      <td>[self, word, max_suggestions]</td>\n",
       "      <td>(self, word, max_suggestions=None):\\n    ' Che...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13447</th>\n",
       "      <td>transform_anagramically</td>\n",
       "      <td>[L]</td>\n",
       "      <td>(L):\\n    d = {}\\n    for e in L:\\n        se ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13448</th>\n",
       "      <td>permutation_representation</td>\n",
       "      <td>[s1, s2]</td>\n",
       "      <td>(s1, s2):\\n    assert (set(s1) == set(s2))\\n  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13449</th>\n",
       "      <td>find_largwst_sq_ana</td>\n",
       "      <td>[tass, squares]</td>\n",
       "      <td>(tass, squares):\\n    S = []\\n    for s in tas...</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13450</th>\n",
       "      <td>findeonadsq</td>\n",
       "      <td>[tass, squares]</td>\n",
       "      <td>(tass, squares):\\n    all_sq_ana = find_larges...</td>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13451</th>\n",
       "      <td>from_docker_envvars</td>\n",
       "      <td>[config]</td>\n",
       "      <td>(config):\\n    if ('PG_PORT' in os.environ):\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13452 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     functionName                         functionArgs  \\\n",
       "0                      load_label                         [label_file]   \n",
       "1                    load_content                          [file_name]   \n",
       "2                   _spawn_aspell  [self, aspell_executable, language]   \n",
       "3           find_misspelled_words     [self, list_of_words, max_words]   \n",
       "4            suggestions_for_word        [self, word, max_suggestions]   \n",
       "...                           ...                                  ...   \n",
       "13447     transform_anagramically                                  [L]   \n",
       "13448  permutation_representation                             [s1, s2]   \n",
       "13449         find_largwst_sq_ana                      [tass, squares]   \n",
       "13450                 findeonadsq                      [tass, squares]   \n",
       "13451         from_docker_envvars                             [config]   \n",
       "\n",
       "                                            functionCode  label  \\\n",
       "0      (label_file):\\n    with open(label_file) as f:...      0   \n",
       "1      (file_name):\\n    with open(file_name) as f:\\n...      0   \n",
       "2      (self, aspell_executable, language):\\n    args...      0   \n",
       "3      (self, list_of_words, max_words=None):\\n    ' ...      0   \n",
       "4      (self, word, max_suggestions=None):\\n    ' Che...      0   \n",
       "...                                                  ...    ...   \n",
       "13447  (L):\\n    d = {}\\n    for e in L:\\n        se ...      0   \n",
       "13448  (s1, s2):\\n    assert (set(s1) == set(s2))\\n  ...      0   \n",
       "13449  (tass, squares):\\n    S = []\\n    for s in tas...      1   \n",
       "13450  (tass, squares):\\n    all_sq_ana = find_larges...      1   \n",
       "13451  (config):\\n    if ('PG_PORT' in os.environ):\\n...      0   \n",
       "\n",
       "                      tokenizedStr  tokenizedStrLen  \n",
       "0      [input_ids, attention_mask]               42  \n",
       "1      [input_ids, attention_mask]               39  \n",
       "2      [input_ids, attention_mask]              153  \n",
       "3      [input_ids, attention_mask]              146  \n",
       "4      [input_ids, attention_mask]              163  \n",
       "...                            ...              ...  \n",
       "13447  [input_ids, attention_mask]               81  \n",
       "13448  [input_ids, attention_mask]              134  \n",
       "13449  [input_ids, attention_mask]              146  \n",
       "13450  [input_ids, attention_mask]              453  \n",
       "13451  [input_ids, attention_mask]              479  \n",
       "\n",
       "[13452 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_fit_df = filt_df_tr[filt_df_tr['tokenizedStrLen'] < 512].reset_index(drop=True)\n",
    "filt_fit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "746faa28-ec91-431b-8bbb-ef61096d635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test_b = tokenizer([n + tokenizer.sep_token + c for n,c in filt_fit_df[['functionName', 'functionCode']].values],\n",
    "                         return_tensors='pt', max_length=512,\n",
    "                         truncation=True, padding='max_length')\n",
    "inputs_test_b['labels'] = torch.LongTensor([filt_fit_df['label'].to_list()]).T\n",
    "dataset_test_b = FunctionsDataset(inputs_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6f352e1-57e8-41c4-9cb6-faaa7736630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13452\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_61518/2919874237.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='841' max='841' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [841/841 02:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.72569236 0.55233809]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.60754793 0.80911436]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90087811 0.41927818]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.1934709548950195,\n",
       " 'eval_accuracy': 0.6598275349390426,\n",
       " 'eval_f1': array([0.72569236, 0.55233809]),\n",
       " 'eval_precision': array([0.60754793, 0.80911436]),\n",
       " 'eval_recall': array([0.90087811, 0.41927818]),\n",
       " 'eval_runtime': 135.162,\n",
       " 'eval_samples_per_second': 99.525,\n",
       " 'eval_steps_per_second': 6.222}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "                                  per_device_eval_batch_size = 16, output_dir = \"test_3b\"\n",
    "                                 )\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer_b = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=dataset_test_b,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_b.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852aaec6-04b3-4211-8b3b-731a027d6b94",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "While fine-tuning on roughly 120MB of data, CodeBERT-base was able to achieve __0.96 F1__ on validation set with __72k__ training function examples, of which roughly 50% were shuffled to be incorrect. Real-life example of the same scenario showed that model is able to correctly identify __all__ of the correct and wrong name functions.\n",
    "\n",
    "With acheived __0.66 accuracy__ (all metrics are pretty much the same on both any-length and full-fit) functions, model was quite unsensitive towards error names, with only 0.55 F1 on the error-class. While certaily being to detect logical misconnections and scoring better than random-guess, the chosen train method on only the correct & shuffled functions __does not prove to be too effective with spelling errors__ - thus to be nerve-proof, we need the training data needs to contain those (and maybe others too) kinds of errors.\n",
    "\n",
    "One possible explanation is byte-level BPE tokenizer here shows to be not sensitive enough, even with few extra/replaced symbols the whole name remains semi-logical.\n",
    "\n",
    "What else to improve? \n",
    "- Embrace in-class (aka \\_\\_this\\_\\_) functions \n",
    "- Find a better way of handling longer functions (bigger context model of course)\n",
    "- Maybe a third hybrid class of error-functions that are logical but not that representative?\n",
    "- Extend binary classification to 'not fitting' / 'syntax error' / etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1088f-212e-476c-add0-923decee2105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
